{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svg_keras_gpt_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJPIMmvkSYuP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29dd94ba-9f94-440e-b5df-a47275696cc6"
      },
      "source": [
        " !nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun  8 11:19:30 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "042LHtVvbNU8",
        "outputId": "4b22b1c1-875e-401f-fcbf-f4726dfb9062"
      },
      "source": [
        "!free -th"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:            12G        611M        8.7G        1.1M        3.4G         11G\n",
            "Swap:            0B          0B          0B\n",
            "Total:          12G        611M        8.7G\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkTOAkZfpybg"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import model_selection\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import random"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FonWzdVUw38-"
      },
      "source": [
        "Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kifJUt1LPUD"
      },
      "source": [
        "DATASET_PATH = 'drive/MyDrive/svg/order_svg_dataset_1000k.csv'\n",
        "\n",
        "def transform_data(data):\n",
        "  def wrap_separators(text):\n",
        "    separators = [r'=', r'\"', r',', r'\\)', r'rgb\\(', r'/>']\n",
        "    replace = [r'=', r'\"', r',', r')', r'rgb(', r'/>']\n",
        "    for sep, rep in zip(separators, replace):\n",
        "      text = re.sub(sep, f' {rep} ', text)\n",
        "    \n",
        "    return text\n",
        "\n",
        "  return np.array([re.sub(' +', ' ', f'# {wrap_separators(x)} $ {wrap_separators(y)} %') for x, y in zip(data['x'], data['y'])])\n",
        "\n",
        "data_train, data_validation = model_selection.train_test_split(pd.read_csv(DATASET_PATH, header=0, usecols=['x', 'y']), test_size=.05)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtVyQhndnDMW"
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "train_text_ds = tf.data.Dataset.from_tensor_slices(transform_data(data_train)).batch(batch_size)\n",
        "validation_text_ds = tf.data.Dataset.from_tensor_slices(transform_data(data_validation)).batch(batch_size)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xYqvGCWVlqB"
      },
      "source": [
        "Load model and vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIDIuZUXVpJy"
      },
      "source": [
        "import pickle\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 300   # Max sequence size\n",
        "EMBEDDING_DIM = 50          # Embedding size for each token\n",
        "NUM_ATTENTION_HEADS = 12    # Number of attention heads\n",
        "FEED_FORWARD_DIM = 256      # Hidden layer size in feed forward network inside transformer\n",
        "NUM_TRANSFORMER_BLOCKS = 5  # Number of transformer blocks\n",
        "\n",
        "def load_text_vectorization(path):\n",
        "    from_disk = pickle.load(open(path, 'rb'))\n",
        "    vectorize_layer = preprocessing.TextVectorization.from_config(from_disk['config'])\n",
        "    vectorize_layer.set_weights(from_disk['weights'])\n",
        "\n",
        "    return vectorize_layer\n",
        "\n",
        "vectorize_layer = load_text_vectorization('drive/MyDrive/svg/vectorize_layer_0_08-06_09-05')\n",
        "vocabulary = vectorize_layer.get_vocabulary()\n",
        "\n",
        "model = keras.models.load_model('drive/MyDrive/svg/model_1_08-06_10-55')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYZ6f97OLwrt"
      },
      "source": [
        "Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuKQUF6oLwYD"
      },
      "source": [
        "# MAX_SEQUENCE_LENGTH = 300   # Max sequence size\n",
        "# EMBEDDING_DIM = 50          # Embedding size for each token\n",
        "# NUM_ATTENTION_HEADS = 12    # Number of attention heads\n",
        "# FEED_FORWARD_DIM = 256      # Hidden layer size in feed forward network inside transformer\n",
        "# NUM_TRANSFORMER_BLOCKS = 5  # Number of transformer blocks\n",
        "\n",
        "# vectorize_layer = layers.experimental.preprocessing.TextVectorization(\n",
        "#     standardize=tf.strings.lower,\n",
        "#     output_mode='int',\n",
        "#     output_sequence_length=MAX_SEQUENCE_LENGTH + 1)\n",
        "\n",
        "# vectorize_layer.adapt(train_text_ds)\n",
        "# vocabulary = vectorize_layer.get_vocabulary() # To get words back from token indices\n",
        "# VOCABULARY_SIZE = len(vocabulary)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Mu-bcME4ZYw"
      },
      "source": [
        "Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCgqFxwJ_Ss0",
        "collapsed": true
      },
      "source": [
        "def causal_attention_mask(batch_size, n_dest, n_src, dtype):\n",
        "    \"\"\"\n",
        "    Mask the upper half of the dot product matrix in self attention.\n",
        "    This prevents flow of information from future tokens to current token.\n",
        "    1's in the lower triangle, counting from the lower right corner.\n",
        "    \"\"\"\n",
        "    i = tf.range(n_dest)[:, None]\n",
        "    j = tf.range(n_src)\n",
        "    m = i >= j - n_src + n_dest\n",
        "    mask = tf.cast(m, dtype)\n",
        "    mask = tf.reshape(mask, [1, n_dest, n_src])\n",
        "    mult = tf.concat(\n",
        "        [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
        "    )\n",
        "    return tf.tile(mask, mult)\n",
        "\n",
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embedding_dim, num_attention_heads, ff_dim, rate=.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_attention_heads, embedding_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation='relu'), layers.Dense(embedding_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size = input_shape[0]\n",
        "        seq_len = input_shape[1]\n",
        "        causal_mask = causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
        "        attention_output = self.att(inputs, inputs, attention_mask=causal_mask)\n",
        "        attention_output = self.dropout1(attention_output)\n",
        "        out1 = self.layernorm1(inputs + attention_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, max_sequence_len, vocabulary_size, embedding_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocabulary_size, output_dim=embedding_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=max_sequence_len, output_dim=embedding_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        positions = tf.range(start=0, limit=tf.shape(x)[-1], delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgJXjiiuJ-oG"
      },
      "source": [
        "def create_model():\n",
        "    inputs = layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
        "    \n",
        "    embedding_layer = TokenAndPositionEmbedding(MAX_SEQUENCE_LENGTH, VOCABULARY_SIZE, EMBEDDING_DIM)\n",
        "    x = embedding_layer(inputs)\n",
        "    for n in range(NUM_TRANSFORMER_BLOCKS):\n",
        "      transformer_block = TransformerBlock(EMBEDDING_DIM, NUM_ATTENTION_HEADS, FEED_FORWARD_DIM)\n",
        "      x = transformer_block(x)\n",
        "    outputs = layers.Dense(VOCABULARY_SIZE)(x)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=[outputs, x])\n",
        "    model.compile(keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                  loss=[tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), None]) # No loss and optimization based on word embeddings from transformer block\n",
        "    return model\n",
        "\n",
        "def prepare_lm_inputs_labels(text):\n",
        "    \"\"\"\n",
        "    Shift word sequences by 1 position so that the target for position (i) is\n",
        "    word at position (i+1). The model will use all words up till position (i)\n",
        "    to predict the next word.\n",
        "    \"\"\"\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    tokenized_sentences = vectorize_layer(text)\n",
        "    x = tokenized_sentences[:, :-1]\n",
        "    y = tokenized_sentences[:, 1:]\n",
        "    return x, y"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MjQFXxXmHDa"
      },
      "source": [
        "Instantiate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onJ4sdQ8l160",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57a28004-324d-4431-dbbf-72a1ebeff0be"
      },
      "source": [
        "# model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 300)]             0         \n",
            "_________________________________________________________________\n",
            "token_and_position_embedding (None, 300, 50)           41450     \n",
            "_________________________________________________________________\n",
            "transformer_block (Transform (None, 300, 50)           147956    \n",
            "_________________________________________________________________\n",
            "transformer_block_1 (Transfo (None, 300, 50)           147956    \n",
            "_________________________________________________________________\n",
            "transformer_block_2 (Transfo (None, 300, 50)           147956    \n",
            "_________________________________________________________________\n",
            "transformer_block_3 (Transfo (None, 300, 50)           147956    \n",
            "_________________________________________________________________\n",
            "transformer_block_4 (Transfo (None, 300, 50)           147956    \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 300, 529)          26979     \n",
            "=================================================================\n",
            "Total params: 808,209\n",
            "Trainable params: 808,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAnnJ_f9mNLV"
      },
      "source": [
        "Instantiate the text generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUIkhCo3OI_x"
      },
      "source": [
        "import svg_generator\n",
        "\n",
        "text_generator = svg_generator.TextGenerator(model, vocabulary, MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec6PQzJ-mR3D"
      },
      "source": [
        "Map data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HTkPfrImVO6"
      },
      "source": [
        "def convert_data(text_ds):\n",
        "  return text_ds.map(prepare_lm_inputs_labels).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "train_data, validation_data = convert_data(train_text_ds), convert_data(validation_text_ds)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1AuCqpDVw9w"
      },
      "source": [
        "Visualise examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOQRFpGjphvn"
      },
      "source": [
        "class CustomEpochEndCallback(keras.callbacks.Callback):\n",
        "  def __init__(self, print_every, callback_function):\n",
        "    self.print_every = print_every\n",
        "    self.callback_function = callback_function\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    if (epoch + 1) % self.print_every != 0:\n",
        "      return\n",
        "\n",
        "    self.callback_function(epoch)\n",
        "\n",
        "\"\"\"\n",
        "Generate and visualise from initial prompts\n",
        "\"\"\"\n",
        "def text_prompts(start_prompts):\n",
        "  for initial_promp in start_prompts:\n",
        "    text_generator.generate(initial_promp)\n",
        "\n",
        "\"\"\"\n",
        "Generate and visualise n entries from the dataset\n",
        "\"\"\"\n",
        "def sample_from_dataset(n=50):\n",
        "  for x, y in data_validation.head(n).values:\n",
        "    text_generator.generate(x)\n",
        "    print('Actual above\\n')\n",
        "    text_generator.display_code(y)\n",
        "    print('Expected above\\n')\n",
        "\n",
        "\"\"\"\n",
        "Save the vectorizer and the model\n",
        "\"\"\"\n",
        "def save_transformer(folder_path, epoch):\n",
        "  import datetime\n",
        "  import pickle\n",
        "  def save_vectorizer(path):\n",
        "    pickle.dump({'config': vectorize_layer.get_config(),\n",
        "                'weights': vectorize_layer.get_weights()},\n",
        "                open(path, 'wb'))\n",
        "  \n",
        "  today = datetime.datetime.today()\n",
        "  date = today.strftime('%d-%m')\n",
        "  time = today.strftime('%H-%M')\n",
        "\n",
        "  save_vectorizer(f'{folder_path}/vectorize_layer_{epoch}_{date}_{time}')\n",
        "  model.save(f'{folder_path}/model_{epoch}_{date}_{time}')\n",
        "\n",
        "callbacks = [\n",
        "  tf.keras.callbacks.ModelCheckpoint('drive/MyDrive/svg/checkpoint', mode='min', save_best_only=True, monitor='loss', save_freq=5000),\n",
        "  CustomEpochEndCallback(1, lambda epoch: save_transformer('drive/MyDrive/svg/', epoch)),\n",
        "  CustomEpochEndCallback(1, lambda epoch: text_prompts(['small red rectangle in bottom left and cyan average circle behind', 'purple large circle in center and green medium circle in front and blue tiny circle in front green medium circle', 'green small rectangle in center and blue tiny circle above and red tiny circle below green small rectangle', 'tiny red rectangle in left, small green rectangle to right, medium blue rectangle to right small green rectangle'])),\n",
        "  CustomEpochEndCallback(2, lambda epoch: sample_from_dataset())\n",
        "]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33LPfJBSXnzO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "407b8e4f-fc56-4e8f-b283-d38e37905692"
      },
      "source": [
        "model.fit(train_data, validation_data=validation_data, verbose=1, initial_epoch=2, epochs=5, callbacks=callbacks)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/5\n",
            " 5000/59375 [=>............................] - ETA: 1:18:48 - loss: 0.2436 - dense_10_loss: 0.2436"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 285). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg/checkpoint/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg/checkpoint/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/59375 [======>.......................] - ETA: 1:04:47 - loss: 0.2435 - dense_10_loss: 0.2435"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 285). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg/checkpoint/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg/checkpoint/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "20000/59375 [=========>....................] - ETA: 57:40 - loss: 0.2434 - dense_10_loss: 0.2434"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 285). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg/checkpoint/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg/checkpoint/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/59375 [===========>..................] - ETA: 50:24 - loss: 0.2434 - dense_10_loss: 0.2434"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 285). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg/checkpoint/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg/checkpoint/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "30000/59375 [==============>...............] - ETA: 43:12 - loss: 0.2433 - dense_10_loss: 0.2433"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 285). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg/checkpoint/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg/checkpoint/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "35000/59375 [================>.............] - ETA: 35:53 - loss: 0.2431 - dense_10_loss: 0.2431"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 285). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg/checkpoint/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg/checkpoint/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "40000/59375 [===================>..........] - ETA: 28:34 - loss: 0.2430 - dense_10_loss: 0.2430"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 285). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg/checkpoint/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg/checkpoint/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "45000/59375 [=====================>........] - ETA: 21:14 - loss: 0.2429 - dense_10_loss: 0.2429"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 285). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg/checkpoint/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg/checkpoint/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/59375 [========================>.....] - ETA: 13:51 - loss: 0.2429 - dense_10_loss: 0.2429"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 285). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg/checkpoint/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg/checkpoint/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "55000/59375 [==========================>...] - ETA: 6:28 - loss: 0.2428 - dense_10_loss: 0.2428"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 285). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg/checkpoint/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg/checkpoint/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "59375/59375 [==============================] - 5403s 91ms/step - loss: 0.2427 - dense_10_loss: 0.2427 - val_loss: 0.2402 - val_dense_10_loss: 0.2402\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 285). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg//model_2_08-06_12-52/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg//model_2_08-06_12-52/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generated text:\n",
            "# small red rectangle in bottom left and cyan average circle behind $ <circle cx = \" 40 \" cy = \" -24 \" r = \" 29 \" fill = \" rgb( 0 , 255 , 255 ) \" stroke-width = \" -1 \" /> <rect x = \" 30 \" y = \" -33 \" width = \" 20 \" height = \" 17 \" fill = \" rgb( 255 , 0 , 0 ) \" stroke-width = \" 0 \" /> % <circle cx = \" 40 \" cy = \" -24 \" r = \" 29 \" fill = \" rgb( 0 , 255 , 255 ) \" stroke-width = \" -1 \" /> <rect x = \" 30 \" y = \" -33 \" width = \" 20 \" height = \" 17 \" fill = \" rgb( 255 , 0 , 0 ) \" stroke-width = \" 0 \" /> %\n",
            "\n",
            "Code:  <circle cx = \" 40 \" cy = \" -24 \" r = \" 29 \" fill = \" rgb( 0 , 255 , 255)\" stroke-width = \" -1 \" /> <rect x = \" 30 \" y = \" -33 \" width = \" 20 \" height = \" 17 \" fill = \" rgb( 255 , 0 , 0)\" stroke-width = \" 0 \" />\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"200\" viewBox=\"0 -200 200 200\" width=\"200\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n      <rect fill=\"white\" height=\"200\" stroke=\"black\" stroke-width=\"2\" width=\"200\" x=\"0\" y=\"-200\"/>\n      <circle cx=\" 40 \" cy=\" -24 \" fill=\" rgb( 0 , 255 , 255)\" r=\" 29 \" stroke-width=\" -1 \"/><rect fill=\" rgb( 255 , 0 , 0)\" height=\" 17 \" stroke-width=\" 0 \" width=\" 20 \" x=\" 30 \" y=\" -33 \"/>\n      </svg>"
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Generated text:\n",
            "# purple large circle in center and green medium circle in front and blue tiny circle in front green medium circle $ <circle cx = \" 94 \" cy = \" -107 \" r = \" 4 \" fill = \" rgb( 0 , 0 , 255 ) \" stroke-width = \" 2 \" /> <circle cx = \" 94 \" cy = \" -107 \" r = \" 29 \" fill = \" rgb( 0 , 255 , 0 ) \" stroke-width = \" 1 \" /> <circle cx = \" 94 \" cy = \" -107 \" r = \" 51 \" fill = \" rgb( 113 , 0 , 132 ) \" stroke-width = \" 0 \" /> % <circle cx = \" 94 \" cy = \" -107 \" r = \" 4 \" fill = \" rgb( 0 , 0 , 255 ) \" stroke-width = \" 2 \" /> <circle cx = \" 94 \" cy = \" -107 \" r = \" 29 \" fill = \" rgb( 0 , 255 , 0 ) \" stroke-width = \" 1 \" /> <circle cx = \" 94 \" cy = \" -107 \" r = \" 51 \" fill = \" rgb( 113 , 0 , 132 ) \" stroke-width = \" 0 \" /> %\n",
            "\n",
            "Code:  <circle cx = \" 94 \" cy = \" -107 \" r = \" 4 \" fill = \" rgb( 0 , 0 , 255)\" stroke-width = \" 2 \" /> <circle cx = \" 94 \" cy = \" -107 \" r = \" 29 \" fill = \" rgb( 0 , 255 , 0)\" stroke-width = \" 1 \" /> <circle cx = \" 94 \" cy = \" -107 \" r = \" 51 \" fill = \" rgb( 113 , 0 , 132)\" stroke-width = \" 0 \" />\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"200\" viewBox=\"0 -200 200 200\" width=\"200\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n      <rect fill=\"white\" height=\"200\" stroke=\"black\" stroke-width=\"2\" width=\"200\" x=\"0\" y=\"-200\"/>\n      <circle cx=\" 94 \" cy=\" -107 \" fill=\" rgb( 113 , 0 , 132)\" r=\" 51 \" stroke-width=\" 0 \"/><circle cx=\" 94 \" cy=\" -107 \" fill=\" rgb( 0 , 255 , 0)\" r=\" 29 \" stroke-width=\" 1 \"/><circle cx=\" 94 \" cy=\" -107 \" fill=\" rgb( 0 , 0 , 255)\" r=\" 4 \" stroke-width=\" 2 \"/>\n      </svg>"
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Generated text:\n",
            "# green small rectangle in center and blue tiny circle above and red tiny circle below green small rectangle $ <circle cx = \" 96 \" cy = \" -38 \" r = \" 4 \" fill = \" rgb( 255 , 0 , 0 ) \" stroke-width = \" 0 \" /> <circle cx = \" 96 \" cy = \" -176 \" r = \" 4 \" fill = \" rgb( 0 , 0 , 255 ) \" stroke-width = \" 0 \" /> <rect x = \" 91 \" y = \" -107 \" width = \" 20 \" height = \" 20 \" fill = \" rgb( 0 , 255 , 0 ) \" stroke-width = \" 0 \" /> % <circle cx = \" 96 \" cy = \" -38 \" r = \" 4 \" fill = \" rgb( 255 , 0 , 0 ) \" stroke-width = \" 0 \" /> <circle cx = \" 96 \" cy = \" -176 \" r = \" 4 \" fill = \" rgb( 0 , 0 , 255 ) \" stroke-width = \" 0 \" /> <rect x = \" 91 \" y = \" -107 \" width = \" 20 \" height = \" 20 \" fill = \" rgb( 0 , 255 , 0 ) \" stroke-width = \" 0 \" /> %\n",
            "\n",
            "Code:  <circle cx = \" 96 \" cy = \" -38 \" r = \" 4 \" fill = \" rgb( 255 , 0 , 0)\" stroke-width = \" 0 \" /> <circle cx = \" 96 \" cy = \" -176 \" r = \" 4 \" fill = \" rgb( 0 , 0 , 255)\" stroke-width = \" 0 \" /> <rect x = \" 91 \" y = \" -107 \" width = \" 20 \" height = \" 20 \" fill = \" rgb( 0 , 255 , 0)\" stroke-width = \" 0 \" />\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"200\" viewBox=\"0 -200 200 200\" width=\"200\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n      <rect fill=\"white\" height=\"200\" stroke=\"black\" stroke-width=\"2\" width=\"200\" x=\"0\" y=\"-200\"/>\n      <circle cx=\" 96 \" cy=\" -176 \" fill=\" rgb( 0 , 0 , 255)\" r=\" 4 \" stroke-width=\" 0 \"/><circle cx=\" 96 \" cy=\" -38 \" fill=\" rgb( 255 , 0 , 0)\" r=\" 4 \" stroke-width=\" 0 \"/><rect fill=\" rgb( 0 , 255 , 0)\" height=\" 20 \" stroke-width=\" 0 \" width=\" 20 \" x=\" 91 \" y=\" -107 \"/>\n      </svg>"
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Generated text:\n",
            "# tiny red rectangle in left , small green rectangle to right , medium blue rectangle to right small green rectangle $ <rect x = \" 169 \" y = \" -125 \" width = \" 63 \" height = \" 61 \" fill = \" rgb( 0 , 0 , 255 ) \" stroke-width = \" 0 \" /> <rect x = \" 89 \" y = \" -107 \" width = \" 20 \" height = \" 20 \" fill = \" rgb( 0 , 255 , 0 ) \" stroke-width = \" 0 \" /> <rect x = \" 32 \" y = \" -103 \" width = \" 10 \" height = \" 10 \" fill = \" rgb( 255 , 0 , 0 ) \" stroke-width = \" 0 \" /> % <rect x = \" 169 \" y = \" -125 \" width = \" 63 \" height = \" 61 \" fill = \" rgb( 0 , 0 , 255 ) \" stroke-width = \" 0 \" /> <rect x = \" 89 \" y = \" -107 \" width = \" 20 \" height = \" 20 \" fill = \" rgb( 0 , 255 , 0 ) \" stroke-width = \" 0 \" /> <rect x = \" 32 \" y = \" -103 \" width = \" 10 \" height = \" 10 \" fill = \" rgb( 255 , 0 , 0 ) \" stroke-width = \" 0 \" /> %\n",
            "\n",
            "Code:  <rect x = \" 169 \" y = \" -125 \" width = \" 63 \" height = \" 61 \" fill = \" rgb( 0 , 0 , 255)\" stroke-width = \" 0 \" /> <rect x = \" 89 \" y = \" -107 \" width = \" 20 \" height = \" 20 \" fill = \" rgb( 0 , 255 , 0)\" stroke-width = \" 0 \" /> <rect x = \" 32 \" y = \" -103 \" width = \" 10 \" height = \" 10 \" fill = \" rgb( 255 , 0 , 0)\" stroke-width = \" 0 \" />\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"200\" viewBox=\"0 -200 200 200\" width=\"200\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n      <rect fill=\"white\" height=\"200\" stroke=\"black\" stroke-width=\"2\" width=\"200\" x=\"0\" y=\"-200\"/>\n      <rect fill=\" rgb( 0 , 0 , 255)\" height=\" 61 \" stroke-width=\" 0 \" width=\" 63 \" x=\" 169 \" y=\" -125 \"/><rect fill=\" rgb( 255 , 0 , 0)\" height=\" 10 \" stroke-width=\" 0 \" width=\" 10 \" x=\" 32 \" y=\" -103 \"/><rect fill=\" rgb( 0 , 255 , 0)\" height=\" 20 \" stroke-width=\" 0 \" width=\" 20 \" x=\" 89 \" y=\" -107 \"/>\n      </svg>"
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/5\n",
            "  625/59375 [..............................] - ETA: 1:27:30 - loss: 0.2423 - dense_10_loss: 0.2423"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 285). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg/checkpoint/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/svg/checkpoint/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 5060/59375 [=>............................] - ETA: 1:21:10 - loss: 0.2422 - dense_10_loss: 0.2422"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-2c0eb8220e97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}